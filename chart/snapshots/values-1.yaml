---
# Source: toggle-django-helm/charts/minio/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: minio
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 9001
        - port: 9000
---
# Source: toggle-django-helm/charts/minio/templates/provisioning-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-app-minio-provisioning
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: minio-provisioning
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
---
# Source: toggle-django-helm/charts/postgresql/templates/primary/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-app-postgres
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
    app.kubernetes.io/component: primary
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 5432
---
# Source: toggle-django-helm/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-app-redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: toggle-django-helm/charts/minio/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: minio
---
# Source: toggle-django-helm/charts/postgresql/templates/primary/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-app-postgres
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
    app.kubernetes.io/component: primary
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
---
# Source: toggle-django-helm/charts/redis/templates/master/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-app-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
    app.kubernetes.io/component: master
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
---
# Source: toggle-django-helm/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
automountServiceAccountToken: false
secrets:
  - name: my-app-minio
---
# Source: toggle-django-helm/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-app-postgres
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
automountServiceAccountToken: false
---
# Source: toggle-django-helm/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: my-app-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
---
# Source: toggle-django-helm/templates/api/service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: secret-account
  annotations:
    
    azure.workload.identity/client-id: XXXXXXXX-YYYYYYYY
  labels:
    
    azure.workload.identity/use: "true"
automountServiceAccountToken: true
---
# Source: toggle-django-helm/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
type: Opaque
data:
  root-user: "bWluaW8tdXNlcg=="
  root-password: "cmFuZG9tLXN0cm9uZy1wYXNzd29yZA=="
---
# Source: toggle-django-helm/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-app-postgres
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
type: Opaque
data:
  postgres-password: "cmFuZG9tLXN0cm9uZy1wYXNzd29yZA=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: toggle-django-helm/templates/config/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: release-name-toggle-django-helm-secret
  labels:
    app: release-name-toggle-django-helm
    environment: ALPHA
    release: release-name
type: Opaque
stringData:
  # secrets
  AWS_S3_ACCESS_KEY_ID: "minio-user"
  AWS_S3_AWS_ENDPOINT_URL: "https://myapp-minio.example.com/"
  AWS_S3_BUCKET_MEDIA_NAME: "media-data"
  AWS_S3_BUCKET_STATIC_NAME: "static-data"
  AWS_S3_REGION: "us-east-1"
  AWS_S3_SECRET_ACCESS_KEY: "random-strong-password"
  POSTGRES_DB: "my-app"
  POSTGRES_HOST: "my-app-postgres"
  POSTGRES_PASSWORD: "random-strong-password"
  POSTGRES_PORT: "5432"
  POSTGRES_USER: "postgres"
  REDIS_URL: "redis://my-app-redis-master:6379/0"
---
# Source: toggle-django-helm/charts/minio/templates/provisioning-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-minio-provisioning
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
    app.kubernetes.io/component: minio-provisioning
data:
---
# Source: toggle-django-helm/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: toggle-django-helm/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: toggle-django-helm/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: toggle-django-helm/templates/config/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: release-name-toggle-django-helm-env-name
  labels:
    app: release-name-toggle-django-helm
    environment: ALPHA
    release: release-name
data:
  # Configs
  ENV_1: "VALUE_1"
---
# Source: toggle-django-helm/charts/minio/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "2Gi"
  storageClassName: longhorn
---
# Source: toggle-django-helm/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
spec:
  type: ClusterIP
  ports:
    - name: minio-api
      port: 9000
      targetPort: minio-api
      nodePort: null
    - name: minio-console
      port: 9001
      targetPort: minio-console
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: minio
---
# Source: toggle-django-helm/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-postgres-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: toggle-django-helm/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-postgres
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: toggle-django-helm/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
---
# Source: toggle-django-helm/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: toggle-django-helm/templates/api/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-toggle-django-helm-api
  labels:
    app: release-name-toggle-django-helm
    component: api
    environment: ALPHA
    release: release-name
spec:
  type: ClusterIP
  selector:
    app: release-name-toggle-django-helm
    component: api
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
---
# Source: toggle-django-helm/templates/celery-flower/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-toggle-django-helm-celery-flower
  labels:
    app: release-name-toggle-django-helm
    component: celery-flower
    environment: ALPHA
    release: release-name
spec:
  type: ClusterIP
  selector:
    app: release-name-toggle-django-helm
    component: worker-flower
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
---
# Source: toggle-django-helm/charts/minio/templates/standalone/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: minio
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: minio
        app.kubernetes.io/version: 2024.12.18
        helm.sh/chart: minio-14.10.5
      annotations:
        checksum/credentials-secret: 72775f6450ba4e322ce9becb3351be5ad755baf03bccc46bf1c06ee46294468f
    spec:
      
      serviceAccountName: my-app-minio
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: minio
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      automountServiceAccountToken: false
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
        supplementalGroups: []
        sysctls: []
      containers:
        - name: minio
          image: docker.io/bitnamilegacy/minio:2024.12.18-debian-12-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MINIO_SCHEME
              value: "http"
            - name: MINIO_FORCE_NEW_KEYS
              value: "yes"
            - name: MINIO_API_PORT_NUMBER
              value: "9000"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: my-app-minio
                  key: root-user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-app-minio
                  key: root-password
            - name: MINIO_DEFAULT_BUCKETS
              value: media-data,static-data
            - name: MINIO_BROWSER
              value: "off"
            - name: MINIO_PROMETHEUS_AUTH_TYPE
              value: "public"
            - name: MINIO_CONSOLE_PORT_NUMBER
              value: "9001"
            - name: MINIO_DATA_DIR
              value: "/bitnami/minio/data"
          envFrom:
          ports:
            - name: minio-api
              containerPort: 9000
              protocol: TCP
            - name: minio-console
              containerPort: 9001
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /minio/health/live
              port: minio-api
              scheme: "HTTP"
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            tcpSocket:
              port: minio-api
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
          resources:
            limits:
              cpu: 375m
              ephemeral-storage: 2Gi
              memory: 384Mi
            requests:
              cpu: 250m
              ephemeral-storage: 50Mi
              memory: 256Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/minio/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /.mc
              subPath: app-mc-dir
            - name: data
              mountPath: /bitnami/minio/data
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: data
          persistentVolumeClaim:
            claimName: my-app-minio
---
# Source: toggle-django-helm/templates/api/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-toggle-django-helm-api
  annotations:
    reloader.stakater.com/auto: "true"
  labels:
    app: release-name-toggle-django-helm
    component: api
    environment: ALPHA
    release: release-name
spec:
  replicas: 1
  selector:
    matchLabels:
      app: release-name-toggle-django-helm
      component: api
  template:
    metadata:
      annotations:
        checksum/secret: b3cd21062f0a8704320dc3846cfef185bb2a8f5854cdb033f2f1092d2d2cca67
        checksum/configmap: de0584c99be865e5e466cd78f1d852c5941906498c945aded88f9c23ada87de0
      labels:
        app: release-name-toggle-django-helm
        component: api
    spec:
      serviceAccountName: secret-account
      containers:
        - name: api
          image: "ghcr.io/example/example:v1.0.1"
          imagePullPolicy: IfNotPresent
          command:
            - /code/deploy/run_prod.sh
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          # TODO: livenessProbe
          resources:
            limits:
              cpu: "2"
              memory: 1Gi
            requests:
              cpu: "0.2"
              memory: 0.5Gi
          envFrom:
            - secretRef:
                name: release-name-toggle-django-helm-secret
            - configMapRef:
                name: release-name-toggle-django-helm-env-name
          env:
            - name: DJANGO_APP_TYPE
              value: "web"
---
# Source: toggle-django-helm/templates/celery-flower/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-toggle-django-helm-celery-flower
  annotations:
    reloader.stakater.com/auto: "true"
  labels:
    app: release-name-toggle-django-helm
    component: worker-flower
    environment: ALPHA
    release: release-name
spec:
  replicas: 1
  selector:
    matchLabels:
      app: release-name-toggle-django-helm
      component: worker-flower
  template:
    metadata:
      annotations:
        checksum/secret: b3cd21062f0a8704320dc3846cfef185bb2a8f5854cdb033f2f1092d2d2cca67
        checksum/configmap: de0584c99be865e5e466cd78f1d852c5941906498c945aded88f9c23ada87de0
      labels:
        app: release-name-toggle-django-helm
        component: worker-flower
    spec:
      serviceAccountName: secret-account
      containers:
        - name: worker
          image: "ghcr.io/example/example:v1.0.1"
          imagePullPolicy: IfNotPresent
          command:
            - celery
            - -A
            - myapp
            - flower
            - --port=8000
          # TODO: livenessProbe
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: "0.1"
              memory: 0.5Gi
          envFrom:
            - secretRef:
                name: release-name-toggle-django-helm-secret
            - configMapRef:
                name: release-name-toggle-django-helm-env-name
          env:
            - name: DJANGO_APP_TYPE
              value: "worker"
---
# Source: toggle-django-helm/templates/worker-beat/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-toggle-django-helm-worker-beat
  annotations:
    reloader.stakater.com/auto: "true"
  labels:
    app: release-name-toggle-django-helm
    component: worker-beat
    environment: ALPHA
    release: release-name
spec:
  replicas: 1  # This should only 1
  selector:
    matchLabels:
      app: release-name-toggle-django-helm
      component: worker-beat
  template:
    metadata:
      annotations:
        checksum/secret: b3cd21062f0a8704320dc3846cfef185bb2a8f5854cdb033f2f1092d2d2cca67
        checksum/configmap: de0584c99be865e5e466cd78f1d852c5941906498c945aded88f9c23ada87de0
      labels:
        app: release-name-toggle-django-helm
        component: worker-beat
    spec:
      serviceAccountName: secret-account
      containers:
        - name: worker-beat
          image: "ghcr.io/example/example:v1.0.1"
          imagePullPolicy: IfNotPresent
          command:
            - celery
            - -A
            - myapp
            - beat
            - -l
            - INFO
          # TODO: livenessProbe
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: "0.1"
              memory: 0.5Gi
          envFrom:
            - secretRef:
                name: release-name-toggle-django-helm-secret
            - configMapRef:
                name: release-name-toggle-django-helm-env-name
          env:
            - name: DJANGO_APP_TYPE
              value: "worker"
---
# Source: toggle-django-helm/templates/worker/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-toggle-django-helm-worker-default
  annotations:
    reloader.stakater.com/auto: "true"
  labels:
    app: release-name-toggle-django-helm
    component: worker
    queue: default
    environment: ALPHA
    release: release-name
spec:
  replicas: 1
  selector:
    matchLabels:
      app: release-name-toggle-django-helm
      component: worker
      queue: default
  template:
    metadata:
      annotations:
        checksum/secret: b3cd21062f0a8704320dc3846cfef185bb2a8f5854cdb033f2f1092d2d2cca67
        checksum/configmap: de0584c99be865e5e466cd78f1d852c5941906498c945aded88f9c23ada87de0
      labels:
        app: release-name-toggle-django-helm
        component: worker
        queue: default
    spec:
      serviceAccountName: secret-account
      containers:
        - name: worker
          command:
            - celery
            - -A
            - myapp
            - worker
            - -l
            - INFO
            - -Q
            - celery
            - --concurrency
            - "4"
            - --max-tasks-per-child
            - "10"
          image: "ghcr.io/example/example:v1.0.1"
          imagePullPolicy: IfNotPresent
          # TODO: livenessProbe
          resources:
            limits:
              cpu: "1"
              memory: 2Gi
            requests:
              cpu: "0.1"
              memory: 1Gi
          envFrom:
            - secretRef:
                name: release-name-toggle-django-helm-secret
            - configMapRef:
                name: release-name-toggle-django-helm-env-name
          env:
            - name: DJANGO_APP_TYPE
              value: "worker"
---
# Source: toggle-django-helm/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-app-postgres
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.4.5
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: my-app-postgres-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-app-postgres
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 17.2.0
        helm.sh/chart: postgresql-16.4.5
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: my-app-postgres
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnamilegacy/postgresql:17.2.0-debian-12-r8
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-app-postgres
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "my-app"
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -d "dbname=my-app" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -d "dbname=my-app" -h 127.0.0.1 -p 5432
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/tmp
              subPath: app-tmp-dir
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "2Gi"
        storageClassName: longhorn
---
# Source: toggle-django-helm/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-app-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.6.3
    app.kubernetes.io/component: master
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: my-app-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.4.2
        helm.sh/chart: redis-20.6.3
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 43cdf68c28f3abe25ce017a82f74dbf2437d1900fd69df51a55a3edf6193d141
        checksum/secret: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: my-app-redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnamilegacy/redis:7.4.2-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: my-app-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: my-app-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: my-app-redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: ".5Gi"
        storageClassName: longhorn
---
# Source: toggle-django-helm/templates/argo-hooks/hook-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-toggle-django-helm-collect-static
  annotations:
    argocd.argoproj.io/hook: PostSync
spec:
  template:
    metadata:
      annotations:
        checksum/secret: b3cd21062f0a8704320dc3846cfef185bb2a8f5854cdb033f2f1092d2d2cca67
        checksum/configmap: de0584c99be865e5e466cd78f1d852c5941906498c945aded88f9c23ada87de0
      labels:
        app: release-name-toggle-django-helm
        component: argo-hooks
    spec:
      restartPolicy: "Never"
      serviceAccountName: secret-account
      containers:
        - name: collect-static
          image: "ghcr.io/example/example:v1.0.1"
          imagePullPolicy: IfNotPresent
          command: 
            - ./manage.py
            - collectstatic
            - --noinput
          resources:
            limits:
              cpu: "4"
              memory: 2Gi
            requests:
              cpu: "0.1"
              memory: 1Gi
          envFrom:
            - secretRef:
                name: release-name-toggle-django-helm-secret
            - configMapRef:
                name: release-name-toggle-django-helm-env-name
          env:
            - name: DJANGO_APP_TYPE
              value: "hook"
---
# Source: toggle-django-helm/templates/argo-hooks/hook-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  generateName: release-name-toggle-django-helm-db-migrate-
  annotations:
    argocd.argoproj.io/hook: PostSync
spec:
  template:
    metadata:
      annotations:
        checksum/secret: b3cd21062f0a8704320dc3846cfef185bb2a8f5854cdb033f2f1092d2d2cca67
        checksum/configmap: de0584c99be865e5e466cd78f1d852c5941906498c945aded88f9c23ada87de0
      labels:
        app: release-name-toggle-django-helm
        component: argo-hooks
    spec:
      restartPolicy: "Never"
      serviceAccountName: secret-account
      containers:
        - name: db-migrate
          image: "ghcr.io/example/example:v1.0.1"
          imagePullPolicy: IfNotPresent
          command: 
            - ./manage.py
            - migrate
          resources:
            limits:
              cpu: "4"
              memory: 2Gi
            requests:
              cpu: "0.1"
              memory: 1Gi
          envFrom:
            - secretRef:
                name: release-name-toggle-django-helm-secret
            - configMapRef:
                name: release-name-toggle-django-helm-env-name
          env:
            - name: DJANGO_APP_TYPE
              value: "hook"
---
# Source: toggle-django-helm/charts/minio/templates/api-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app-minio-api
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 50m
spec:
  ingressClassName: "nginx"
  rules:
    - host: myapp-minio.example.com
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: my-app-minio
                port:
                  name: minio-api
---
# Source: toggle-django-helm/templates/api/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-toggle-django-helm-api
  labels:
    app: release-name-toggle-django-helm
    component: api
    environment: ALPHA
    release: release-name
spec:
  ingressClassName: "nginx"
  rules:
    - host: "myapp.example.com"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: release-name-toggle-django-helm-api
                port:
                  number: 80
  tls:
    - secretName: my-secret
      hosts:
        - "myapp.example.com"
---
# Source: toggle-django-helm/templates/extraManifests.yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: pg-cluster
spec:
  backup: {}
  enablePDB: true
  instances: 3
  monitoring:
    enablePodMonitor: true
  plugins:
  - isWALArchiver: true
    name: barman-cloud.cloudnative-pg.io
    parameters:
      barmanObjectName: aws-s3-store
  storage:
    size: 300Mi
---
# Source: toggle-django-helm/templates/extraManifests.yaml
apiVersion: barmancloud.cnpg.io/v1
kind: ObjectStore
metadata:
  name: aws-s3-store
spec:
  configuration:
    destinationPath: s3://my-db-backup/barman/
    s3Credentials:
      accessKeyId:
        key: ACCESS_KEY_ID
        name: barman-s3-creds
      secretAccessKey:
        key: ACCESS_SECRET_KEY
        name: barman-s3-creds
    wal:
      compression: gzip
      maxParallel: 4
  retentionPolicy: 30d
---
# Source: toggle-django-helm/templates/extraManifests.yaml
apiVersion: postgresql.cnpg.io/v1
kind: ScheduledBackup
metadata:
  name: backup-daily
spec:
  backupOwnerReference: self
  cluster:
    name: pg-cluster
  immediate: true
  method: plugin
  pluginConfiguration:
    name: barman-cloud.cloudnative-pg.io
  schedule: 0 0 0 * * *
  suspend: false
---
# Source: toggle-django-helm/charts/minio/templates/provisioning-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-app-minio-provisioning
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.12.18
    helm.sh/chart: minio-14.10.5
    app.kubernetes.io/component: minio-provisioning
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
spec: 
  ttlSecondsAfterFinished: 600 
  parallelism: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: 2024.12.18
        helm.sh/chart: minio-14.10.5
        app.kubernetes.io/component: minio-provisioning
    spec:
      
      restartPolicy: OnFailure
      terminationGracePeriodSeconds: 0
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: my-app-minio
      initContainers:
        - name: wait-for-available-minio
          image: docker.io/bitnami/os-shell:12-debian-12-r35
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
            - -c
            - |-
              set -e;
              echo "Waiting for Minio";
              wait-for-port \
                --host=my-app-minio \
                --state=inuse \
                --timeout=120 \
                9000;
              echo "Minio is available";
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
      containers:
        - name: minio
          image: docker.io/bitnamilegacy/minio:2024.12.18-debian-12-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
            - -c
            - |-
              set -e;
              echo "Start Minio provisioning";

              retry_while() {
                local -r cmd="${1:?cmd is missing}"
                local -r retries="${2:-12}"
                local -r sleep_time="${3:-5}"
                local return_value=1

                read -r -a command <<< "$cmd"
                for ((i = 1 ; i <= retries ; i+=1 )); do
                    "${command[@]}" && return_value=0 && break
                    sleep "$sleep_time"
                done
                return $return_value
              }

              function attachPolicy() {
                local tmp=$(mc admin $1 info provisioning $2 | sed -n -e 's/^Policy.*: \(.*\)$/\1/p');
                IFS=',' read -r -a CURRENT_POLICIES <<< "$tmp";
                if [[ ! "${CURRENT_POLICIES[*]}" =~ "$3" ]]; then
                  mc admin policy attach provisioning $3 --$1=$2;
                fi;
              };

              function detachDanglingPolicies() {
                local tmp=$(mc admin $1 info provisioning $2 | sed -n -e 's/^Policy.*: \(.*\)$/\1/p');
                IFS=',' read -r -a CURRENT_POLICIES <<< "$tmp";
                IFS=',' read -r -a DESIRED_POLICIES <<< "$3";
                for current in "${CURRENT_POLICIES[@]}"; do
                  if [[ ! "${DESIRED_POLICIES[*]}" =~ "${current}" ]]; then
                    mc admin policy detach provisioning $current --$1=$2;
                  fi;
                done;
              }

              function addUsersFromFile() {
                local username=$(grep -oP '^username=\K.+' $1);
                local password=$(grep -oP '^password=\K.+' $1);
                local disabled=$(grep -oP '^disabled=\K.+' $1);
                local policies_list=$(grep -oP '^policies=\K.+' $1);
                local set_policies=$(grep -oP '^setPolicies=\K.+' $1);

                mc admin user add provisioning "${username}" "${password}";

                IFS=',' read -r -a POLICIES <<< "${policies_list}";
                for policy in "${POLICIES[@]}"; do
                  attachPolicy user "${username}" "${policy}";
                done;
                if [ "${set_policies}" == "true" ]; then
                  detachDanglingPolicies user "${username}" "${policies_list}";
                fi;

                local user_status="enable";
                if [[ "${disabled}" != "" && "${disabled,,}" == "true" ]]; then
                  user_status="disable";
                fi;

                mc admin user "${user_status}" provisioning "${username}";
              };
              mc alias set provisioning $MINIO_SCHEME://my-app-minio:9000 $MINIO_ROOT_USER $MINIO_ROOT_PASSWORD;

              mc admin service restart provisioning --wait --json;

              # Adding a sleep to ensure that the check below does not cause
              # a race condition. We check for the MinIO port because the
              # "mc admin service restart --wait" command is not working as expected
              sleep 5;
              echo "Waiting for Minio to be available after restart";
              if ! retry_while "mc admin info provisioning"; then
                  echo "Error connecting to Minio"
                  exit 1
              fi
              echo "Minio is available. Executing provisioning commands";
              
              mc anonymous set download provisioning/static-data;

              echo "End Minio provisioning";
          env:
            - name: MINIO_SCHEME
              value: "http"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: my-app-minio
                  key: root-user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-app-minio
                  key: root-password
          envFrom:
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /.mc
              subPath: app-mc-dir
            - name: empty-dir
              mountPath: /opt/bitnami/minio/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: minio-provisioning
              mountPath: /etc/ilm
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: minio-provisioning
          configMap:
            name: my-app-minio-provisioning
